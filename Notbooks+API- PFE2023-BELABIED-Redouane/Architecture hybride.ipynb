{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bibliotheques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-01T10:13:23.411914Z",
     "iopub.status.busy": "2023-02-01T10:13:23.411506Z",
     "iopub.status.idle": "2023-02-01T10:13:29.756015Z",
     "shell.execute_reply": "2023-02-01T10:13:29.754992Z",
     "shell.execute_reply.started": "2023-02-01T10:13:23.411834Z"
    }
   },
   "outputs": [],
   "source": [
    "#Importation des bibliotheques necessaires\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "from distutils.dir_util import copy_tree, remove_tree\n",
    "\n",
    "from PIL import Image\n",
    "from random import randint\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import matthews_corrcoef as MCC\n",
    "from sklearn.metrics import balanced_accuracy_score as BAS\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from joblib import dump, load\n",
    "\n",
    "import tensorflow_addons as tfa\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from tensorflow.keras import Sequential, Input\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.layers import Conv2D, Flatten\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.applications.vgg19 import VGG19\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator as IDG\n",
    "from tensorflow.keras.layers import SeparableConv2D, BatchNormalization, GlobalAveragePooling2D\n",
    "\n",
    "\n",
    "print(\"TensorFlow Version:\", tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-01T10:13:29.758382Z",
     "iopub.status.busy": "2023-02-01T10:13:29.758011Z",
     "iopub.status.idle": "2023-02-01T10:13:53.520400Z",
     "shell.execute_reply": "2023-02-01T10:13:53.519407Z",
     "shell.execute_reply.started": "2023-02-01T10:13:29.758340Z"
    }
   },
   "outputs": [],
   "source": [
    "#Dossiers des dataset\n",
    "\n",
    "base_dir = \"../dataset/\"\n",
    "root_dir = \"./\"\n",
    "work_dir = root_dir + \"adni/\"\n",
    "#work_dir = root_dir + \"kaggle/\"\n",
    "    \n",
    "print(\"Working Directory Contents:\", os.listdir(work_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-01T10:13:53.522344Z",
     "iopub.status.busy": "2023-02-01T10:13:53.521829Z",
     "iopub.status.idle": "2023-02-01T10:13:53.527034Z",
     "shell.execute_reply": "2023-02-01T10:13:53.526082Z",
     "shell.execute_reply.started": "2023-02-01T10:13:53.522304Z"
    }
   },
   "outputs": [],
   "source": [
    "#Initialisation des classes et la taille des images\n",
    "WORK_DIR = './adni/'\n",
    "\n",
    "CLASSES = ['AD','MCI','CN']\n",
    "\n",
    "IMG_SIZE = 176\n",
    "IMAGE_SIZE = [176, 176]\n",
    "DIM = (IMG_SIZE, IMG_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-01T10:13:53.529069Z",
     "iopub.status.busy": "2023-02-01T10:13:53.528459Z",
     "iopub.status.idle": "2023-02-01T10:13:53.855683Z",
     "shell.execute_reply": "2023-02-01T10:13:53.854604Z",
     "shell.execute_reply.started": "2023-02-01T10:13:53.529034Z"
    }
   },
   "outputs": [],
   "source": [
    "#Augmentation des données\n",
    "\n",
    "ZOOM = [.99, 1.01]\n",
    "BRIGHT_RANGE = [0.8, 1.2]\n",
    "HORZ_FLIP = False\n",
    "FILL_MODE = \"constant\"\n",
    "DATA_FORMAT = \"channels_last\"\n",
    "\n",
    "work_dr = IDG(rescale = 1./255, brightness_range=BRIGHT_RANGE, zoom_range=ZOOM, data_format=DATA_FORMAT, fill_mode=FILL_MODE, horizontal_flip=HORZ_FLIP)\n",
    "\n",
    "train_data_gen = work_dr.flow_from_directory(directory=WORK_DIR, target_size=DIM, batch_size=6000, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalisation\n",
    "image_pixels = train_data.reshape(-1, train_data.shape[-1])\n",
    "\n",
    "# Creation MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(image_pixels)\n",
    "\n",
    "# Transformer les pixels en [0, 1]\n",
    "image_pixels = scaler.transform(image_pixels)\n",
    "\n",
    "# Retoure au demention originale des images\n",
    "train_data = image_pixels.reshape(train_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-01T10:13:53.859015Z",
     "iopub.status.busy": "2023-02-01T10:13:53.858752Z",
     "iopub.status.idle": "2023-02-01T10:13:53.866575Z",
     "shell.execute_reply": "2023-02-01T10:13:53.865697Z",
     "shell.execute_reply.started": "2023-02-01T10:13:53.858988Z"
    }
   },
   "outputs": [],
   "source": [
    "#Affichage des images irm\n",
    "\"\"\"def show_images(generator,y_pred=None):\n",
    "    \n",
    "    Input: An image generator,predicted labels (optional)\n",
    "    Output: Displays a grid of 9 images with lables\n",
    "    \n",
    "    \n",
    "    # get image lables\n",
    "    labels =dict(zip([0,1,2,3], CLASSES))\n",
    "    \n",
    "    # get a batch of images\n",
    "    x,y = generator.next()\n",
    "    \n",
    "    # display a grid of 9 images\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    if y_pred is None:\n",
    "        for i in range(9):\n",
    "            ax = plt.subplot(3, 3, i + 1)\n",
    "            idx = randint(0, 6400)\n",
    "            plt.imshow(x[idx])\n",
    "            plt.axis(\"off\")\n",
    "            plt.title(\"Class:{}\".format(labels[np.argmax(y[idx])]))\n",
    "                                                     \n",
    "    else:\n",
    "        for i in range(9):\n",
    "            ax = plt.subplot(3, 3, i + 1)\n",
    "            plt.imshow(x[i])\n",
    "            plt.axis(\"off\")\n",
    "            plt.title(\"Actual:{} \\nPredicted:{}\".format(labels[np.argmax(y[i])],labels[y_pred[i]]))\n",
    "    \n",
    "# Display Train Images\n",
    "show_images(train_data_gen)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-01T10:13:53.870603Z",
     "iopub.status.busy": "2023-02-01T10:13:53.870062Z",
     "iopub.status.idle": "2023-02-01T10:14:37.374290Z",
     "shell.execute_reply": "2023-02-01T10:14:37.373402Z",
     "shell.execute_reply.started": "2023-02-01T10:13:53.870565Z"
    }
   },
   "outputs": [],
   "source": [
    "#Récupérer les données à partir de l'itérateur ImageDataGenerator.\n",
    "\n",
    "train_data, train_labels = train_data_gen.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-01T10:14:37.375893Z",
     "iopub.status.busy": "2023-02-01T10:14:37.375541Z",
     "iopub.status.idle": "2023-02-01T10:14:37.381686Z",
     "shell.execute_reply": "2023-02-01T10:14:37.380764Z",
     "shell.execute_reply.started": "2023-02-01T10:14:37.375857Z"
    }
   },
   "outputs": [],
   "source": [
    "#Les dimensions des données\n",
    "\n",
    "print(train_data.shape, train_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-01T10:14:37.383559Z",
     "iopub.status.busy": "2023-02-01T10:14:37.383031Z",
     "iopub.status.idle": "2023-02-01T10:15:12.907515Z",
     "shell.execute_reply": "2023-02-01T10:15:12.906580Z",
     "shell.execute_reply.started": "2023-02-01T10:14:37.383523Z"
    }
   },
   "outputs": [],
   "source": [
    "#Effectuer une sur-échantillonnage (OverSampling) des données, car les classes sont déséquilibrées.\n",
    "\n",
    "sm = SMOTE(random_state=42)\n",
    "\n",
    "train_data, train_labels = sm.fit_resample(train_data.reshape(-1, IMG_SIZE * IMG_SIZE * 3), train_labels)\n",
    "\n",
    "train_data = train_data.reshape(-1, IMG_SIZE, IMG_SIZE, 3)\n",
    "\n",
    "print(train_data.shape, train_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extraction des caracterestiques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importer le modele pre entraine VGG19 (import weights)\n",
    "vgg = VGG19(input_shape=(176, 176, 3), include_top=False, weights=\"imagenet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importer le modele pre entraine InceptionV3 (import weights)\n",
    "inception = InceptionV3(input_shape=(176, 176, 3), include_top=False, weights=\"imagenet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extraction des caracterestiques depuis VGG19\n",
    "batch_size = 32\n",
    "vgg_features = []\n",
    "\n",
    "for i in range(0, len(train_data), batch_size):\n",
    "  batch = train_data[i:i+batch_size]  \n",
    "  batch_features = vgg.predict(batch)\n",
    "  vgg_features.append(batch_features)\n",
    "\n",
    "vgg_features = np.concatenate(vgg_features, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extraction des caracterestiques depuis InceptionV3\n",
    "batch_size = 32\n",
    "inception_features = []\n",
    "\n",
    "for i in range(0, len(train_data), batch_size):\n",
    "  batch = train_data[i:i+batch_size]  \n",
    "  batch_features = inception.predict(batch)\n",
    "  inception_features.append(batch_features)\n",
    "\n",
    "inception_features = np.concatenate(inception_features, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Redimentionner les caracterestiques de VGG19 en vecteur 2D\n",
    "vgg_features=vgg_features.reshape(vgg_features.shape[0], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Redimentionner les caracterestiques de InceptionV3 en vecteur 2D\n",
    "inception_features=inception_features.reshape(vgg_features.shape[0], -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatination et Splittng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#La concatination des caracterestiques\n",
    "features = np.concatenate([vgg_features, inception_features], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Affectaion des caracterestiques a nouvelle variable pour passer au SVM\n",
    "X = features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Affectation des labels\n",
    "Y=train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Diviser les données en ensembles d'entraînement et de test.\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrainement de svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Le modele SVM\n",
    "svm = SVC(kernel='linear', C=0.6, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Entrainement de SVM\n",
    "svm.fit(X_train, np.argmax(Y_train, axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test et resultats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prediction sur les données de test\n",
    "Y_pred = svm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calcule de Accuracy\n",
    "accuracy = accuracy_score(np.argmax(Y_test, axis=1), Y_pred)\n",
    "print('Accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Redimentionnemnt en matrice\n",
    "n_classes = len(np.unique(Y_pred))\n",
    "Y_pred = np.eye(n_classes)[Y_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Matrice de confusion\n",
    "pred_ls = np.argmax(Y_pred, axis=1)\n",
    "test_ls = np.argmax(Y_test, axis=1)\n",
    "conf_matrix = confusion_matrix(test_ls, pred_ls)\n",
    "\n",
    "# Normalize \n",
    "conf_matrix_norm = conf_matrix / conf_matrix.sum(axis=1)[:,np.newaxis] \n",
    "\n",
    "plt.figure(figsize=(8, 6), dpi=80, facecolor='w', edgecolor='k')\n",
    "ax = sns.heatmap(conf_matrix_norm, \n",
    "                cmap='Blues', \n",
    "                annot=True, \n",
    "                fmt='.2%',\n",
    "                xticklabels=CLASSES,\n",
    "                yticklabels=CLASSES)\n",
    "\n",
    "#plt.title('Normalized Confusion Matrix')\n",
    "plt.xlabel('Classe prédite')\n",
    "plt.ylabel('Classe réelle')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Le rapport de classification : precision, reccall, f1 score\n",
    "\n",
    "def roundoff(arr):\n",
    "    \"\"\"To round off according to the argmax of each predicted label array. \"\"\"\n",
    "    arr[np.argwhere(arr != arr.max())] = 0\n",
    "    arr[np.argwhere(arr == arr.max())] = 1\n",
    "    return arr\n",
    "\n",
    "for labels in Y_pred:\n",
    "    labels = roundoff(labels)\n",
    "\n",
    "print(classification_report(Y_test, Y_pred, target_names=CLASSES))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sauvgarde des modeles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sauvgarde de modeles VGG19 et InceptionV3 pour extraction des caracterestiques\n",
    "\n",
    "#VGG19\n",
    "vgg_model_dir = work_dir + \"vgg_model\"\n",
    "vgg.save(vgg_model_dir, save_format='h5')\n",
    "os.listdir(work_dir)\n",
    "\n",
    "#InceptionV3\n",
    "inception_model_dir = work_dir + \"inception_model\"\n",
    "inception.save(inception_model_dir, save_format='h5')\n",
    "os.listdir(work_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sauvgarde de modele SVM\n",
    "model_folder = '../Saved models/'\n",
    "model_filename = 'svm_model.sav'\n",
    "model_path = os.path.join(model_folder, model_filename)\n",
    "dump(svm, model_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
